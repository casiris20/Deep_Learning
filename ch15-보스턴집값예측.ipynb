{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝을 구동하는 데 필요한 케라스 함수를 불러옵니다.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 필요한 라이브러리를 불러옵니다.\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "seed=0\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분입니다.\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2   3      4      5     6       7   8      9     10  \\\n",
       "0    0.00632  18.0   2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1    0.02731   0.0   7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2    0.02729   0.0   7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3    0.03237   0.0   2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4    0.06905   0.0   2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "..       ...   ...    ...  ..    ...    ...   ...     ...  ..    ...   ...   \n",
       "501  0.06263   0.0  11.93   0  0.573  6.593  69.1  2.4786   1  273.0  21.0   \n",
       "502  0.04527   0.0  11.93   0  0.573  6.120  76.7  2.2875   1  273.0  21.0   \n",
       "503  0.06076   0.0  11.93   0  0.573  6.976  91.0  2.1675   1  273.0  21.0   \n",
       "504  0.10959   0.0  11.93   0  0.573  6.794  89.3  2.3889   1  273.0  21.0   \n",
       "505  0.04741   0.0  11.93   0  0.573  6.030  80.8  2.5050   1  273.0  21.0   \n",
       "\n",
       "         11    12    13  \n",
       "0    396.90  4.98  24.0  \n",
       "1    396.90  9.14  21.6  \n",
       "2    392.83  4.03  34.7  \n",
       "3    394.63  2.94  33.4  \n",
       "4    396.90  5.33  36.2  \n",
       "..      ...   ...   ...  \n",
       "501  391.99  9.67  22.4  \n",
       "502  396.90  9.08  20.6  \n",
       "503  396.90  5.64  23.9  \n",
       "504  393.45  6.48  22.0  \n",
       "505  396.90  7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/housing.csv',delim_whitespace=True, header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values\n",
    "X = dataset[:,0:-1]\n",
    "Y = dataset[:,-1]\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))\n",
    "\n",
    "model.add(Dense(12,  activation='relu'))\n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 14.6575\n",
      "Epoch 2/300\n",
      "36/36 [==============================] - 0s 875us/step - loss: 13.9021\n",
      "Epoch 3/300\n",
      "36/36 [==============================] - 0s 889us/step - loss: 13.8429\n",
      "Epoch 4/300\n",
      "36/36 [==============================] - 0s 866us/step - loss: 13.6948\n",
      "Epoch 5/300\n",
      "36/36 [==============================] - 0s 782us/step - loss: 12.8307\n",
      "Epoch 6/300\n",
      "36/36 [==============================] - 0s 891us/step - loss: 12.8394\n",
      "Epoch 7/300\n",
      "36/36 [==============================] - 0s 865us/step - loss: 12.7664\n",
      "Epoch 8/300\n",
      "36/36 [==============================] - 0s 855us/step - loss: 12.7315\n",
      "Epoch 9/300\n",
      "36/36 [==============================] - 0s 843us/step - loss: 13.9430\n",
      "Epoch 10/300\n",
      "36/36 [==============================] - 0s 832us/step - loss: 13.1528\n",
      "Epoch 11/300\n",
      "36/36 [==============================] - 0s 895us/step - loss: 12.3685\n",
      "Epoch 12/300\n",
      "36/36 [==============================] - 0s 775us/step - loss: 11.8877\n",
      "Epoch 13/300\n",
      "36/36 [==============================] - 0s 812us/step - loss: 12.1076\n",
      "Epoch 14/300\n",
      "36/36 [==============================] - 0s 773us/step - loss: 14.6260\n",
      "Epoch 15/300\n",
      "36/36 [==============================] - 0s 756us/step - loss: 14.5452\n",
      "Epoch 16/300\n",
      "36/36 [==============================] - 0s 776us/step - loss: 12.6637\n",
      "Epoch 17/300\n",
      "36/36 [==============================] - 0s 791us/step - loss: 13.0718\n",
      "Epoch 18/300\n",
      "36/36 [==============================] - 0s 822us/step - loss: 12.5266\n",
      "Epoch 19/300\n",
      "36/36 [==============================] - 0s 800us/step - loss: 12.1759\n",
      "Epoch 20/300\n",
      "36/36 [==============================] - 0s 777us/step - loss: 12.1583\n",
      "Epoch 21/300\n",
      "36/36 [==============================] - 0s 781us/step - loss: 12.2723\n",
      "Epoch 22/300\n",
      "36/36 [==============================] - 0s 797us/step - loss: 13.1603\n",
      "Epoch 23/300\n",
      "36/36 [==============================] - 0s 868us/step - loss: 13.9266\n",
      "Epoch 24/300\n",
      "36/36 [==============================] - 0s 832us/step - loss: 17.9247\n",
      "Epoch 25/300\n",
      "36/36 [==============================] - 0s 862us/step - loss: 12.8293\n",
      "Epoch 26/300\n",
      "36/36 [==============================] - 0s 774us/step - loss: 12.7514\n",
      "Epoch 27/300\n",
      "36/36 [==============================] - 0s 802us/step - loss: 13.4607\n",
      "Epoch 28/300\n",
      "36/36 [==============================] - 0s 833us/step - loss: 12.9175\n",
      "Epoch 29/300\n",
      "36/36 [==============================] - 0s 837us/step - loss: 13.2062\n",
      "Epoch 30/300\n",
      "36/36 [==============================] - 0s 930us/step - loss: 12.8090\n",
      "Epoch 31/300\n",
      "36/36 [==============================] - 0s 845us/step - loss: 12.0428\n",
      "Epoch 32/300\n",
      "36/36 [==============================] - 0s 873us/step - loss: 13.9712\n",
      "Epoch 33/300\n",
      "36/36 [==============================] - 0s 857us/step - loss: 16.1085\n",
      "Epoch 34/300\n",
      "36/36 [==============================] - 0s 901us/step - loss: 13.1809\n",
      "Epoch 35/300\n",
      "36/36 [==============================] - 0s 903us/step - loss: 12.2228\n",
      "Epoch 36/300\n",
      "36/36 [==============================] - 0s 885us/step - loss: 12.9796\n",
      "Epoch 37/300\n",
      "36/36 [==============================] - 0s 872us/step - loss: 13.6398\n",
      "Epoch 38/300\n",
      "36/36 [==============================] - 0s 849us/step - loss: 11.7115\n",
      "Epoch 39/300\n",
      "36/36 [==============================] - 0s 871us/step - loss: 11.8669\n",
      "Epoch 40/300\n",
      "36/36 [==============================] - 0s 863us/step - loss: 12.3915\n",
      "Epoch 41/300\n",
      "36/36 [==============================] - 0s 914us/step - loss: 13.2955\n",
      "Epoch 42/300\n",
      "36/36 [==============================] - 0s 901us/step - loss: 11.9282\n",
      "Epoch 43/300\n",
      "36/36 [==============================] - 0s 849us/step - loss: 13.0126\n",
      "Epoch 44/300\n",
      "36/36 [==============================] - 0s 852us/step - loss: 13.9007\n",
      "Epoch 45/300\n",
      "36/36 [==============================] - 0s 805us/step - loss: 12.3165\n",
      "Epoch 46/300\n",
      "36/36 [==============================] - 0s 790us/step - loss: 12.4085\n",
      "Epoch 47/300\n",
      "36/36 [==============================] - 0s 775us/step - loss: 13.4155\n",
      "Epoch 48/300\n",
      "36/36 [==============================] - 0s 780us/step - loss: 14.5734\n",
      "Epoch 49/300\n",
      "36/36 [==============================] - 0s 829us/step - loss: 12.9289\n",
      "Epoch 50/300\n",
      "36/36 [==============================] - 0s 815us/step - loss: 12.4063\n",
      "Epoch 51/300\n",
      "36/36 [==============================] - 0s 776us/step - loss: 12.0533\n",
      "Epoch 52/300\n",
      "36/36 [==============================] - 0s 771us/step - loss: 12.2000\n",
      "Epoch 53/300\n",
      "36/36 [==============================] - 0s 767us/step - loss: 12.4335\n",
      "Epoch 54/300\n",
      "36/36 [==============================] - 0s 958us/step - loss: 11.7099\n",
      "Epoch 55/300\n",
      "36/36 [==============================] - 0s 828us/step - loss: 11.5893\n",
      "Epoch 56/300\n",
      "36/36 [==============================] - 0s 753us/step - loss: 13.4546\n",
      "Epoch 57/300\n",
      "36/36 [==============================] - 0s 743us/step - loss: 11.1527\n",
      "Epoch 58/300\n",
      "36/36 [==============================] - 0s 770us/step - loss: 11.7292\n",
      "Epoch 59/300\n",
      "36/36 [==============================] - 0s 779us/step - loss: 11.6389\n",
      "Epoch 60/300\n",
      "36/36 [==============================] - 0s 745us/step - loss: 11.9491\n",
      "Epoch 61/300\n",
      "36/36 [==============================] - 0s 724us/step - loss: 11.9941\n",
      "Epoch 62/300\n",
      "36/36 [==============================] - 0s 776us/step - loss: 11.1380\n",
      "Epoch 63/300\n",
      "36/36 [==============================] - 0s 838us/step - loss: 11.6574\n",
      "Epoch 64/300\n",
      "36/36 [==============================] - 0s 786us/step - loss: 10.9926\n",
      "Epoch 65/300\n",
      "36/36 [==============================] - 0s 814us/step - loss: 14.3788\n",
      "Epoch 66/300\n",
      "36/36 [==============================] - 0s 843us/step - loss: 13.1520\n",
      "Epoch 67/300\n",
      "36/36 [==============================] - 0s 818us/step - loss: 10.6708\n",
      "Epoch 68/300\n",
      "36/36 [==============================] - 0s 741us/step - loss: 11.6178\n",
      "Epoch 69/300\n",
      "36/36 [==============================] - 0s 758us/step - loss: 10.8901\n",
      "Epoch 70/300\n",
      "36/36 [==============================] - 0s 742us/step - loss: 11.4800\n",
      "Epoch 71/300\n",
      "36/36 [==============================] - 0s 774us/step - loss: 10.8244\n",
      "Epoch 72/300\n",
      "36/36 [==============================] - 0s 837us/step - loss: 12.3123\n",
      "Epoch 73/300\n",
      "36/36 [==============================] - 0s 850us/step - loss: 10.7966\n",
      "Epoch 74/300\n",
      "36/36 [==============================] - 0s 859us/step - loss: 11.7127\n",
      "Epoch 75/300\n",
      "36/36 [==============================] - 0s 882us/step - loss: 14.9755\n",
      "Epoch 76/300\n",
      "36/36 [==============================] - 0s 838us/step - loss: 12.4359\n",
      "Epoch 77/300\n",
      "36/36 [==============================] - 0s 890us/step - loss: 12.0945\n",
      "Epoch 78/300\n",
      "36/36 [==============================] - 0s 833us/step - loss: 12.0764\n",
      "Epoch 79/300\n",
      "36/36 [==============================] - 0s 864us/step - loss: 11.0036\n",
      "Epoch 80/300\n",
      "36/36 [==============================] - 0s 877us/step - loss: 10.9704\n",
      "Epoch 81/300\n",
      "36/36 [==============================] - 0s 812us/step - loss: 10.6768\n",
      "Epoch 82/300\n",
      "36/36 [==============================] - 0s 849us/step - loss: 11.7891\n",
      "Epoch 83/300\n",
      "36/36 [==============================] - 0s 883us/step - loss: 11.1205\n",
      "Epoch 84/300\n",
      "36/36 [==============================] - 0s 832us/step - loss: 10.8602\n",
      "Epoch 85/300\n",
      "36/36 [==============================] - 0s 848us/step - loss: 12.8478\n",
      "Epoch 86/300\n",
      "36/36 [==============================] - 0s 846us/step - loss: 12.4926\n",
      "Epoch 87/300\n",
      "36/36 [==============================] - 0s 842us/step - loss: 11.3196\n",
      "Epoch 88/300\n",
      "36/36 [==============================] - 0s 857us/step - loss: 11.8342\n",
      "Epoch 89/300\n",
      "36/36 [==============================] - 0s 828us/step - loss: 11.2660\n",
      "Epoch 90/300\n",
      "36/36 [==============================] - 0s 827us/step - loss: 11.2962\n",
      "Epoch 91/300\n",
      "36/36 [==============================] - 0s 855us/step - loss: 10.6778\n",
      "Epoch 92/300\n",
      "36/36 [==============================] - 0s 816us/step - loss: 11.9089\n",
      "Epoch 93/300\n",
      "36/36 [==============================] - 0s 829us/step - loss: 11.7872\n",
      "Epoch 94/300\n",
      "36/36 [==============================] - 0s 817us/step - loss: 11.7388\n",
      "Epoch 95/300\n",
      "36/36 [==============================] - 0s 738us/step - loss: 11.2134\n",
      "Epoch 96/300\n",
      "36/36 [==============================] - 0s 928us/step - loss: 11.1515\n",
      "Epoch 97/300\n",
      "36/36 [==============================] - 0s 805us/step - loss: 10.8834\n",
      "Epoch 98/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 774us/step - loss: 10.6419\n",
      "Epoch 99/300\n",
      "36/36 [==============================] - 0s 782us/step - loss: 12.2281\n",
      "Epoch 100/300\n",
      "36/36 [==============================] - 0s 742us/step - loss: 10.5639\n",
      "Epoch 101/300\n",
      "36/36 [==============================] - 0s 766us/step - loss: 10.6966\n",
      "Epoch 102/300\n",
      "36/36 [==============================] - 0s 833us/step - loss: 10.4989\n",
      "Epoch 103/300\n",
      "36/36 [==============================] - 0s 838us/step - loss: 10.9460\n",
      "Epoch 104/300\n",
      "36/36 [==============================] - 0s 765us/step - loss: 12.4191\n",
      "Epoch 105/300\n",
      "36/36 [==============================] - 0s 785us/step - loss: 18.4858\n",
      "Epoch 106/300\n",
      "36/36 [==============================] - 0s 744us/step - loss: 11.7037\n",
      "Epoch 107/300\n",
      "36/36 [==============================] - 0s 747us/step - loss: 11.3709\n",
      "Epoch 108/300\n",
      "36/36 [==============================] - 0s 751us/step - loss: 10.5832\n",
      "Epoch 109/300\n",
      "36/36 [==============================] - 0s 758us/step - loss: 11.3380\n",
      "Epoch 110/300\n",
      "36/36 [==============================] - 0s 717us/step - loss: 10.9539\n",
      "Epoch 111/300\n",
      "36/36 [==============================] - ETA: 0s - loss: 9.559 - 0s 746us/step - loss: 10.1138\n",
      "Epoch 112/300\n",
      "36/36 [==============================] - 0s 803us/step - loss: 10.0747\n",
      "Epoch 113/300\n",
      "36/36 [==============================] - 0s 778us/step - loss: 10.7303\n",
      "Epoch 114/300\n",
      "36/36 [==============================] - 0s 774us/step - loss: 11.0866\n",
      "Epoch 115/300\n",
      "36/36 [==============================] - 0s 711us/step - loss: 10.7668\n",
      "Epoch 116/300\n",
      "36/36 [==============================] - 0s 739us/step - loss: 10.5342\n",
      "Epoch 117/300\n",
      "36/36 [==============================] - 0s 790us/step - loss: 10.7723\n",
      "Epoch 118/300\n",
      "36/36 [==============================] - 0s 748us/step - loss: 10.9311\n",
      "Epoch 119/300\n",
      "36/36 [==============================] - 0s 750us/step - loss: 11.8218\n",
      "Epoch 120/300\n",
      "36/36 [==============================] - 0s 717us/step - loss: 10.5408\n",
      "Epoch 121/300\n",
      "36/36 [==============================] - 0s 694us/step - loss: 11.5379\n",
      "Epoch 122/300\n",
      "36/36 [==============================] - 0s 711us/step - loss: 10.9845\n",
      "Epoch 123/300\n",
      "36/36 [==============================] - 0s 690us/step - loss: 11.9398\n",
      "Epoch 124/300\n",
      "36/36 [==============================] - 0s 673us/step - loss: 11.8049\n",
      "Epoch 125/300\n",
      "36/36 [==============================] - 0s 750us/step - loss: 12.6698\n",
      "Epoch 126/300\n",
      "36/36 [==============================] - 0s 678us/step - loss: 11.6723\n",
      "Epoch 127/300\n",
      "36/36 [==============================] - 0s 695us/step - loss: 11.5388\n",
      "Epoch 128/300\n",
      "36/36 [==============================] - 0s 738us/step - loss: 11.0118\n",
      "Epoch 129/300\n",
      "36/36 [==============================] - 0s 766us/step - loss: 11.6488\n",
      "Epoch 130/300\n",
      "36/36 [==============================] - 0s 759us/step - loss: 11.9853\n",
      "Epoch 131/300\n",
      "36/36 [==============================] - 0s 719us/step - loss: 9.8706\n",
      "Epoch 132/300\n",
      "36/36 [==============================] - 0s 799us/step - loss: 10.7006\n",
      "Epoch 133/300\n",
      "36/36 [==============================] - 0s 791us/step - loss: 10.7189\n",
      "Epoch 134/300\n",
      "36/36 [==============================] - 0s 776us/step - loss: 11.3181\n",
      "Epoch 135/300\n",
      "36/36 [==============================] - 0s 780us/step - loss: 10.4176\n",
      "Epoch 136/300\n",
      "36/36 [==============================] - 0s 791us/step - loss: 10.8334\n",
      "Epoch 137/300\n",
      "36/36 [==============================] - 0s 727us/step - loss: 10.8682\n",
      "Epoch 138/300\n",
      "36/36 [==============================] - 0s 786us/step - loss: 10.8559\n",
      "Epoch 139/300\n",
      "36/36 [==============================] - 0s 788us/step - loss: 10.8011\n",
      "Epoch 140/300\n",
      "36/36 [==============================] - 0s 770us/step - loss: 12.1215\n",
      "Epoch 141/300\n",
      "36/36 [==============================] - 0s 788us/step - loss: 11.0523\n",
      "Epoch 142/300\n",
      "36/36 [==============================] - 0s 722us/step - loss: 10.9975\n",
      "Epoch 143/300\n",
      "36/36 [==============================] - 0s 812us/step - loss: 10.9518\n",
      "Epoch 144/300\n",
      "36/36 [==============================] - 0s 811us/step - loss: 10.7079\n",
      "Epoch 145/300\n",
      "36/36 [==============================] - 0s 804us/step - loss: 11.1201\n",
      "Epoch 146/300\n",
      "36/36 [==============================] - 0s 776us/step - loss: 10.7497\n",
      "Epoch 147/300\n",
      "36/36 [==============================] - 0s 747us/step - loss: 9.6252\n",
      "Epoch 148/300\n",
      "36/36 [==============================] - 0s 722us/step - loss: 10.5349\n",
      "Epoch 149/300\n",
      "36/36 [==============================] - 0s 732us/step - loss: 10.5868\n",
      "Epoch 150/300\n",
      "36/36 [==============================] - 0s 814us/step - loss: 10.7229\n",
      "Epoch 151/300\n",
      "36/36 [==============================] - 0s 810us/step - loss: 12.5585\n",
      "Epoch 152/300\n",
      "36/36 [==============================] - 0s 767us/step - loss: 11.5909\n",
      "Epoch 153/300\n",
      "36/36 [==============================] - 0s 800us/step - loss: 10.4062\n",
      "Epoch 154/300\n",
      "36/36 [==============================] - 0s 724us/step - loss: 10.8614\n",
      "Epoch 155/300\n",
      "36/36 [==============================] - 0s 710us/step - loss: 10.2123\n",
      "Epoch 156/300\n",
      "36/36 [==============================] - 0s 793us/step - loss: 11.7127\n",
      "Epoch 157/300\n",
      "36/36 [==============================] - 0s 812us/step - loss: 11.0580\n",
      "Epoch 158/300\n",
      "36/36 [==============================] - 0s 772us/step - loss: 10.0514\n",
      "Epoch 159/300\n",
      "36/36 [==============================] - 0s 793us/step - loss: 10.1226\n",
      "Epoch 160/300\n",
      "36/36 [==============================] - 0s 738us/step - loss: 10.3215\n",
      "Epoch 161/300\n",
      "36/36 [==============================] - 0s 732us/step - loss: 11.3046\n",
      "Epoch 162/300\n",
      "36/36 [==============================] - 0s 750us/step - loss: 10.6739\n",
      "Epoch 163/300\n",
      "36/36 [==============================] - 0s 760us/step - loss: 11.6964\n",
      "Epoch 164/300\n",
      "36/36 [==============================] - 0s 736us/step - loss: 11.3963\n",
      "Epoch 165/300\n",
      "36/36 [==============================] - 0s 764us/step - loss: 9.9283\n",
      "Epoch 166/300\n",
      "36/36 [==============================] - 0s 786us/step - loss: 11.4852\n",
      "Epoch 167/300\n",
      "36/36 [==============================] - 0s 835us/step - loss: 10.7059\n",
      "Epoch 168/300\n",
      "36/36 [==============================] - 0s 779us/step - loss: 9.9666\n",
      "Epoch 169/300\n",
      "36/36 [==============================] - 0s 858us/step - loss: 10.3333\n",
      "Epoch 170/300\n",
      "36/36 [==============================] - 0s 800us/step - loss: 10.0142\n",
      "Epoch 171/300\n",
      "36/36 [==============================] - 0s 811us/step - loss: 9.6671\n",
      "Epoch 172/300\n",
      "36/36 [==============================] - 0s 771us/step - loss: 9.8976\n",
      "Epoch 173/300\n",
      "36/36 [==============================] - 0s 756us/step - loss: 11.0602\n",
      "Epoch 174/300\n",
      "36/36 [==============================] - 0s 826us/step - loss: 11.0663\n",
      "Epoch 175/300\n",
      "36/36 [==============================] - 0s 810us/step - loss: 10.3968\n",
      "Epoch 176/300\n",
      "36/36 [==============================] - 0s 818us/step - loss: 9.9683\n",
      "Epoch 177/300\n",
      "36/36 [==============================] - 0s 773us/step - loss: 11.1847\n",
      "Epoch 178/300\n",
      "36/36 [==============================] - 0s 839us/step - loss: 9.8510\n",
      "Epoch 179/300\n",
      "36/36 [==============================] - 0s 777us/step - loss: 9.8697\n",
      "Epoch 180/300\n",
      "36/36 [==============================] - 0s 706us/step - loss: 9.7854\n",
      "Epoch 181/300\n",
      "36/36 [==============================] - 0s 793us/step - loss: 9.8225\n",
      "Epoch 182/300\n",
      "36/36 [==============================] - 0s 832us/step - loss: 10.1166\n",
      "Epoch 183/300\n",
      "36/36 [==============================] - 0s 800us/step - loss: 9.8382\n",
      "Epoch 184/300\n",
      "36/36 [==============================] - 0s 814us/step - loss: 11.4056\n",
      "Epoch 185/300\n",
      "36/36 [==============================] - 0s 718us/step - loss: 10.1672\n",
      "Epoch 186/300\n",
      "36/36 [==============================] - 0s 688us/step - loss: 9.8913\n",
      "Epoch 187/300\n",
      "36/36 [==============================] - 0s 713us/step - loss: 9.7095\n",
      "Epoch 188/300\n",
      "36/36 [==============================] - 0s 722us/step - loss: 10.2327\n",
      "Epoch 189/300\n",
      "36/36 [==============================] - 0s 714us/step - loss: 9.3535\n",
      "Epoch 190/300\n",
      "36/36 [==============================] - 0s 702us/step - loss: 10.9507\n",
      "Epoch 191/300\n",
      "36/36 [==============================] - 0s 740us/step - loss: 12.2743\n",
      "Epoch 192/300\n",
      "36/36 [==============================] - 0s 703us/step - loss: 10.5888\n",
      "Epoch 193/300\n",
      "36/36 [==============================] - 0s 724us/step - loss: 9.3773\n",
      "Epoch 194/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 734us/step - loss: 10.9962\n",
      "Epoch 195/300\n",
      "36/36 [==============================] - 0s 727us/step - loss: 9.5955\n",
      "Epoch 196/300\n",
      "36/36 [==============================] - 0s 740us/step - loss: 9.9871\n",
      "Epoch 197/300\n",
      "36/36 [==============================] - 0s 819us/step - loss: 10.1140\n",
      "Epoch 198/300\n",
      "36/36 [==============================] - 0s 829us/step - loss: 10.5317\n",
      "Epoch 199/300\n",
      "36/36 [==============================] - 0s 769us/step - loss: 9.2274\n",
      "Epoch 200/300\n",
      "36/36 [==============================] - 0s 745us/step - loss: 10.3326\n",
      "Epoch 201/300\n",
      "36/36 [==============================] - 0s 750us/step - loss: 10.2504\n",
      "Epoch 202/300\n",
      "36/36 [==============================] - 0s 806us/step - loss: 9.1414\n",
      "Epoch 203/300\n",
      "36/36 [==============================] - 0s 932us/step - loss: 9.8384\n",
      "Epoch 204/300\n",
      "36/36 [==============================] - 0s 897us/step - loss: 9.8503\n",
      "Epoch 205/300\n",
      "36/36 [==============================] - 0s 877us/step - loss: 9.6703\n",
      "Epoch 206/300\n",
      "36/36 [==============================] - 0s 899us/step - loss: 9.6025\n",
      "Epoch 207/300\n",
      "36/36 [==============================] - 0s 917us/step - loss: 12.4240\n",
      "Epoch 208/300\n",
      "36/36 [==============================] - 0s 909us/step - loss: 10.3840\n",
      "Epoch 209/300\n",
      "36/36 [==============================] - 0s 865us/step - loss: 9.6392\n",
      "Epoch 210/300\n",
      "36/36 [==============================] - 0s 779us/step - loss: 9.2442\n",
      "Epoch 211/300\n",
      "36/36 [==============================] - 0s 771us/step - loss: 9.7634\n",
      "Epoch 212/300\n",
      "36/36 [==============================] - 0s 724us/step - loss: 9.3530\n",
      "Epoch 213/300\n",
      "36/36 [==============================] - 0s 742us/step - loss: 10.1618\n",
      "Epoch 214/300\n",
      "36/36 [==============================] - 0s 782us/step - loss: 10.4330\n",
      "Epoch 215/300\n",
      "36/36 [==============================] - 0s 793us/step - loss: 10.1333\n",
      "Epoch 216/300\n",
      "36/36 [==============================] - 0s 788us/step - loss: 9.4390\n",
      "Epoch 217/300\n",
      "36/36 [==============================] - 0s 778us/step - loss: 11.0503\n",
      "Epoch 218/300\n",
      "36/36 [==============================] - 0s 748us/step - loss: 9.2158\n",
      "Epoch 219/300\n",
      "36/36 [==============================] - 0s 730us/step - loss: 9.1266\n",
      "Epoch 220/300\n",
      "36/36 [==============================] - 0s 755us/step - loss: 11.6410\n",
      "Epoch 221/300\n",
      "36/36 [==============================] - 0s 760us/step - loss: 10.1834\n",
      "Epoch 222/300\n",
      "36/36 [==============================] - 0s 708us/step - loss: 9.3279\n",
      "Epoch 223/300\n",
      "36/36 [==============================] - 0s 750us/step - loss: 9.6280\n",
      "Epoch 224/300\n",
      "36/36 [==============================] - 0s 766us/step - loss: 9.2041\n",
      "Epoch 225/300\n",
      "36/36 [==============================] - 0s 752us/step - loss: 9.7669\n",
      "Epoch 226/300\n",
      "36/36 [==============================] - 0s 722us/step - loss: 9.3395\n",
      "Epoch 227/300\n",
      "36/36 [==============================] - 0s 728us/step - loss: 9.5977\n",
      "Epoch 228/300\n",
      "36/36 [==============================] - 0s 834us/step - loss: 9.7343\n",
      "Epoch 229/300\n",
      "36/36 [==============================] - 0s 761us/step - loss: 9.4182\n",
      "Epoch 230/300\n",
      "36/36 [==============================] - 0s 773us/step - loss: 10.5579\n",
      "Epoch 231/300\n",
      "36/36 [==============================] - 0s 735us/step - loss: 9.7428\n",
      "Epoch 232/300\n",
      "36/36 [==============================] - 0s 734us/step - loss: 9.6169\n",
      "Epoch 233/300\n",
      "36/36 [==============================] - 0s 770us/step - loss: 9.2945\n",
      "Epoch 234/300\n",
      "36/36 [==============================] - 0s 815us/step - loss: 9.5387\n",
      "Epoch 235/300\n",
      "36/36 [==============================] - 0s 778us/step - loss: 9.1561\n",
      "Epoch 236/300\n",
      "36/36 [==============================] - 0s 794us/step - loss: 9.0176\n",
      "Epoch 237/300\n",
      "36/36 [==============================] - 0s 755us/step - loss: 9.4174\n",
      "Epoch 238/300\n",
      "36/36 [==============================] - 0s 790us/step - loss: 10.0893\n",
      "Epoch 239/300\n",
      "36/36 [==============================] - 0s 898us/step - loss: 10.0139\n",
      "Epoch 240/300\n",
      "36/36 [==============================] - 0s 903us/step - loss: 10.3848\n",
      "Epoch 241/300\n",
      "36/36 [==============================] - 0s 889us/step - loss: 9.7443\n",
      "Epoch 242/300\n",
      "36/36 [==============================] - 0s 952us/step - loss: 9.0152\n",
      "Epoch 243/300\n",
      "36/36 [==============================] - 0s 878us/step - loss: 9.4844\n",
      "Epoch 244/300\n",
      "36/36 [==============================] - 0s 790us/step - loss: 9.4996\n",
      "Epoch 245/300\n",
      "36/36 [==============================] - 0s 700us/step - loss: 10.0894\n",
      "Epoch 246/300\n",
      "36/36 [==============================] - 0s 731us/step - loss: 9.3823\n",
      "Epoch 247/300\n",
      "36/36 [==============================] - 0s 782us/step - loss: 9.9112\n",
      "Epoch 248/300\n",
      "36/36 [==============================] - 0s 751us/step - loss: 9.8878\n",
      "Epoch 249/300\n",
      "36/36 [==============================] - 0s 698us/step - loss: 9.3486\n",
      "Epoch 250/300\n",
      "36/36 [==============================] - 0s 709us/step - loss: 10.0126\n",
      "Epoch 251/300\n",
      "36/36 [==============================] - 0s 743us/step - loss: 10.8502\n",
      "Epoch 252/300\n",
      "36/36 [==============================] - 0s 741us/step - loss: 8.8273\n",
      "Epoch 253/300\n",
      "36/36 [==============================] - 0s 701us/step - loss: 9.0020\n",
      "Epoch 254/300\n",
      "36/36 [==============================] - 0s 710us/step - loss: 9.8654\n",
      "Epoch 255/300\n",
      "36/36 [==============================] - 0s 756us/step - loss: 10.4676\n",
      "Epoch 256/300\n",
      "36/36 [==============================] - 0s 681us/step - loss: 9.3914\n",
      "Epoch 257/300\n",
      "36/36 [==============================] - 0s 724us/step - loss: 10.4842\n",
      "Epoch 258/300\n",
      "36/36 [==============================] - 0s 747us/step - loss: 10.5314\n",
      "Epoch 259/300\n",
      "36/36 [==============================] - 0s 699us/step - loss: 9.8300\n",
      "Epoch 260/300\n",
      "36/36 [==============================] - 0s 738us/step - loss: 9.0632\n",
      "Epoch 261/300\n",
      "36/36 [==============================] - 0s 738us/step - loss: 10.1089\n",
      "Epoch 262/300\n",
      "36/36 [==============================] - 0s 705us/step - loss: 10.0616\n",
      "Epoch 263/300\n",
      "36/36 [==============================] - 0s 722us/step - loss: 8.9953\n",
      "Epoch 264/300\n",
      "36/36 [==============================] - 0s 783us/step - loss: 8.8885\n",
      "Epoch 265/300\n",
      "36/36 [==============================] - 0s 740us/step - loss: 10.1056\n",
      "Epoch 266/300\n",
      "36/36 [==============================] - 0s 720us/step - loss: 9.2054\n",
      "Epoch 267/300\n",
      "36/36 [==============================] - 0s 736us/step - loss: 8.8496\n",
      "Epoch 268/300\n",
      "36/36 [==============================] - 0s 808us/step - loss: 8.9844\n",
      "Epoch 269/300\n",
      "36/36 [==============================] - 0s 802us/step - loss: 9.4489\n",
      "Epoch 270/300\n",
      "36/36 [==============================] - 0s 751us/step - loss: 8.7019\n",
      "Epoch 271/300\n",
      "36/36 [==============================] - 0s 739us/step - loss: 9.1084\n",
      "Epoch 272/300\n",
      "36/36 [==============================] - 0s 707us/step - loss: 8.9747\n",
      "Epoch 273/300\n",
      "36/36 [==============================] - 0s 798us/step - loss: 9.6335\n",
      "Epoch 274/300\n",
      "36/36 [==============================] - 0s 767us/step - loss: 8.9455\n",
      "Epoch 275/300\n",
      "36/36 [==============================] - 0s 770us/step - loss: 10.4421\n",
      "Epoch 276/300\n",
      "36/36 [==============================] - 0s 708us/step - loss: 10.6142\n",
      "Epoch 277/300\n",
      "36/36 [==============================] - 0s 728us/step - loss: 8.9730\n",
      "Epoch 278/300\n",
      "36/36 [==============================] - 0s 800us/step - loss: 8.3498\n",
      "Epoch 279/300\n",
      "36/36 [==============================] - 0s 728us/step - loss: 8.4292\n",
      "Epoch 280/300\n",
      "36/36 [==============================] - 0s 701us/step - loss: 8.8918\n",
      "Epoch 281/300\n",
      "36/36 [==============================] - 0s 735us/step - loss: 9.5614\n",
      "Epoch 282/300\n",
      "36/36 [==============================] - 0s 785us/step - loss: 10.2638\n",
      "Epoch 283/300\n",
      "36/36 [==============================] - 0s 749us/step - loss: 8.6328\n",
      "Epoch 284/300\n",
      "36/36 [==============================] - 0s 741us/step - loss: 8.1889\n",
      "Epoch 285/300\n",
      "36/36 [==============================] - 0s 739us/step - loss: 8.2493\n",
      "Epoch 286/300\n",
      "36/36 [==============================] - 0s 760us/step - loss: 9.8372\n",
      "Epoch 287/300\n",
      "36/36 [==============================] - 0s 758us/step - loss: 8.7180\n",
      "Epoch 288/300\n",
      "36/36 [==============================] - 0s 748us/step - loss: 8.9795\n",
      "Epoch 289/300\n",
      "36/36 [==============================] - 0s 741us/step - loss: 10.5977\n",
      "Epoch 290/300\n",
      "36/36 [==============================] - 0s 741us/step - loss: 9.4840\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 787us/step - loss: 9.7052\n",
      "Epoch 292/300\n",
      "36/36 [==============================] - 0s 802us/step - loss: 9.3313\n",
      "Epoch 293/300\n",
      "36/36 [==============================] - 0s 745us/step - loss: 9.6410\n",
      "Epoch 294/300\n",
      "36/36 [==============================] - 0s 747us/step - loss: 8.1360\n",
      "Epoch 295/300\n",
      "36/36 [==============================] - 0s 757us/step - loss: 9.0642\n",
      "Epoch 296/300\n",
      "36/36 [==============================] - 0s 786us/step - loss: 8.8404\n",
      "Epoch 297/300\n",
      "36/36 [==============================] - 0s 745us/step - loss: 8.6956\n",
      "Epoch 298/300\n",
      "36/36 [==============================] - 0s 715us/step - loss: 8.7437\n",
      "Epoch 299/300\n",
      "36/36 [==============================] - 0s 743us/step - loss: 8.5885\n",
      "Epoch 300/300\n",
      "36/36 [==============================] - 0s 745us/step - loss: 8.8145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1feab333348>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=300, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격 : 22.600, 예상가격 : 27.106\n",
      "실제가격 : 50.000, 예상가격 : 26.033\n",
      "실제가격 : 23.000, 예상가격 : 25.903\n",
      "실제가격 : 8.300, 예상가격 : 11.588\n",
      "실제가격 : 21.200, 예상가격 : 19.262\n",
      "실제가격 : 19.900, 예상가격 : 22.253\n",
      "실제가격 : 20.600, 예상가격 : 23.834\n",
      "실제가격 : 18.700, 예상가격 : 22.820\n",
      "실제가격 : 16.100, 예상가격 : 15.513\n",
      "실제가격 : 18.600, 예상가격 : 12.835\n"
     ]
    }
   ],
   "source": [
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10) : \n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print('실제가격 : {:.3f}, 예상가격 : {:.3f}'.format(label, prediction))\n",
    "    \n",
    "    ## epochs : 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격 : 22.600, 예상가격 : 27.586\n",
      "실제가격 : 50.000, 예상가격 : 25.710\n",
      "실제가격 : 23.000, 예상가격 : 27.375\n",
      "실제가격 : 8.300, 예상가격 : 9.162\n",
      "실제가격 : 21.200, 예상가격 : 20.272\n",
      "실제가격 : 19.900, 예상가격 : 22.007\n",
      "실제가격 : 20.600, 예상가격 : 21.590\n",
      "실제가격 : 18.700, 예상가격 : 22.108\n",
      "실제가격 : 16.100, 예상가격 : 16.778\n",
      "실제가격 : 18.600, 예상가격 : 10.221\n"
     ]
    }
   ],
   "source": [
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10) : \n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print('실제가격 : {:.3f}, 예상가격 : {:.3f}'.format(label, prediction))\n",
    "    \n",
    "    ## epochs : 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'datetime.datetime'>\n",
      "2018-09-15 00:01:14\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "strtype = '2018-09-15 00:01:14'\n",
    "print(type(strtype))\n",
    "\n",
    "logdate = datetime.strptime(strtype, '%Y-%m-%d %H:%M:%S')\n",
    "print(type(logdate))\n",
    "print(logdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
